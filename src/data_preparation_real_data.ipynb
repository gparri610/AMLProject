{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering and Preparation\n",
    "This notebook is aimed at showing the most important steps of the implemented data preparation. Part of the data preparation is calles as a function. Readers interested in all the specifics steps taken should consult the data_handling.py file in the data_handling folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from data_handling import rawdf_to_stockdfs, get_features, batch_tensor, df_list_to_series_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_parquet('../data/data.parquet.gzip')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NA values and amplifying the data with handcrafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use ffill later\n",
    "raw_df.sort_values(by=['stock_id', 'time_id'], inplace=True)\n",
    "\n",
    "# Fill NA values with 0 when possible and using the last valid observation otherwise\n",
    "raw_df.fillna({\n",
    "    'far_price': 0,\n",
    "    'near_price': 0,\n",
    "    'imbalance_size': raw_df['imbalance_size'].ffill(),\n",
    "    'reference_price': raw_df['reference_price'].ffill(),\n",
    "    'matched_size': raw_df['matched_size'].ffill(),\n",
    "    'bid_price': raw_df['bid_price'].ffill(),\n",
    "    'ask_price': raw_df['ask_price'].ffill(),\n",
    "    'wap': raw_df['wap'].ffill()\n",
    "}, inplace=True)\n",
    "\n",
    "# Amplifying the Data with Features engineered by hand\n",
    "amp_df = get_features(raw_df)\n",
    "\n",
    "# Reordering the columns to ensure Targets is the last column\n",
    "new_order = [col for col in amp_df.columns if col != 'target'] + ['target']\n",
    "amp_df = amp_df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with missing targets\n",
    "amp_df = amp_df.dropna()\n",
    "assert amp_df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training, validation and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = amp_df[amp_df['date_id'] < 100]\n",
    "df_train = df_train.sort_values(by=['stock_id', 'time_id'], inplace=False)\n",
    "\n",
    "df_validation = amp_df[amp_df['date_id'] > 99]\n",
    "df_validation = df_validation[df_validation['date_id'] < 120]\n",
    "df_validation = df_validation.sort_values(by=['stock_id', 'time_id'], inplace=False)\n",
    "\n",
    "df_test = amp_df[amp_df['date_id'] > 119]\n",
    "df_test = df_test[df_test['date_id'] < 140]\n",
    "df_test = df_test.sort_values(by=['stock_id', 'time_id'], inplace=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Data\n",
    "# The first four will later be dropped and the target column will be scaled differently\n",
    "excluded_columns = ['stock_id', 'date_id', 'time_id', 'row_id', 'target']\n",
    "\n",
    "# Standardize only the columns that are not in the excluded list\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Scaling the Training Data\n",
    "df_train[df_train.columns.difference(excluded_columns)] = feature_scaler.fit_transform(df_train[df_train.columns.difference(excluded_columns)])\n",
    "df_train[['target']] = target_scaler.fit_transform(df_train[['target']])\n",
    "\n",
    "# Scaling the Validation Data\n",
    "df_validation[df_validation.columns.difference(excluded_columns)] = feature_scaler.transform(df_validation[df_validation.columns.difference(excluded_columns)])\n",
    "df_validation[['target']] = target_scaler.transform(df_validation[['target']])\n",
    "\n",
    "# Scaling the Test Data\n",
    "df_test[df_test.columns.difference(excluded_columns)] = feature_scaler.transform(df_test[df_test.columns.difference(excluded_columns)])\n",
    "df_test[['target']] = target_scaler.transform(df_test[['target']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data by stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist_train = rawdf_to_stockdfs(df_train)\n",
    "dflist_validation = rawdf_to_stockdfs(df_validation)\n",
    "dflist_test = rawdf_to_stockdfs(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequences and Batches of Sequences from that\n",
    "\n",
    "We create batches in order to speed up computations and to stabilize the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sequence_length = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Turning data into sequences\n",
    "collected_tensor_train = df_list_to_series_tensor(dflist_train, sequence_length, shuffle=True)\n",
    "collected_tensor_test = df_list_to_series_tensor(dflist_test, sequence_length, shuffle=True)\n",
    "collected_tensor_validation = df_list_to_series_tensor(dflist_validation, sequence_length, shuffle=True)\n",
    "\n",
    "# Turning the aggregated sequences into batches\n",
    "batches_train = batch_tensor(collected_tensor_train, batch_size)\n",
    "batches_validation = batch_tensor(collected_tensor_test, batch_size)\n",
    "batches_test = batch_tensor(collected_tensor_validation, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('processed_data'):\n",
    "    os.makedirs('processed_data')\n",
    "\n",
    "torch.save(batches_train, 'processed_data/batches_train.pt')\n",
    "torch.save(batches_validation, 'processed_data/batches_validation.pt')\n",
    "torch.save(batches_test, 'processed_data/batches_test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
